# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - testing
    - python
    - .net
title: 'PYCON UK 2017: Automated data exploration edit'
language: English
recordingDate: 1509580159
description: "VÃ­ctor Zabalza | Friday 11:30 | Room C\n\nThe first step in any data-intensive project is understanding the available data. To this end, data scientists spend a significant part of their time carrying out data quality assessments and data exploration. In spite of this being a crucial step, it usually requires repeating a series of menial tasks before the data scientist gains an understanding ofthe dataset and can progress to the next steps in the project.\n\nIn this talk I will detail the inner workings of a Python package that we have built which automates this drudge work, enables efficient data exploration, and kickstarts data science projects. A summary is generated for each dataset, including:\n\n    General information about the dataset, including data quality of each of the columns;\n    Distribution of each of the columns through statistics and plots (histogram, CDF, KDE), optionally grouped by other categorical variables;\n    2D distribution between pairs of columns;\n    Correlation coefficient matrix for all numerical columns.\n\nBuilding this tool has provided a unique view into the full Python data stack, from the parallelised analysis of a dataframe within a Dask custom execution graph, to the interactive visualisation with Jupyter widgets and Plotly. During the talk, I will also introduce how Dask works, and demonstrate how to migrate data pipelines to take advantage of its scalable capabilities.\n\nSlides: https://www.slideshare.net/VictorZabalza/automated-data-exploration-building-efficient-analysis-pipelines-with-dask-81328214"
