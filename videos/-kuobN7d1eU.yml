# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - storage
    - redis
    - performance
    - containers
    - python
title: 'valentin - Compress Me, Stupid!'
recordingDate: 1411368816
description: "valentin - Compress Me, Stupid!\n[EuroPython 2014]\n[23 July 2014]\n\nCompression is a general technique for reducing the size of datasets that normally lie on disk or that should be sent remotely.  But time has come to use it as a means to accelerate applications that uses in-memory data too.\nBlosc is a high-performance meta-compressor that is meant to do that.\n\n-----\n\nCompression is a technique to reduce the number of bits needed to\nrepresent a given dataset. A very common use-case in the distributed\ndigital age is to reduce the size of files in order to reduce the time\nand bandwidth requirements of sending a file from one location to\nanother.\n\nThere are a large variety of different algorithms and implementations of\nso called \"codecs\" - a term is derived from the fact that programs that\nimplement a compression algorithm commonly constitute of both a\ncompressor and a corresponding decompressor. There are many different\nspecial purpose compressors that exploit specifics in the structure of the\ninput data, for example: MP3, Ogg and FLAC for audio data such as music,\nGIF, JPEG and PNG for images and  MPEG for encoding video. Also, there\nare many general purpose codecs that make no assumptions about the\nstructure of the data, for example: Zlib(DEFLATE), Bzip2(BWT) and LZMA.\n\nHowever, and due to the ever growing divide between memory access latency and CPU clock\nspeed a new use-case beyond faster file transfers and more efficient use\nof disk-space has emerged: \"in-memory compression\".\n\n\nKeeping data in RAM that is compressed also means that the CPU has to\ndo more work in order to make use of it.  However, if the compressor\nis fast enough, this decompression overhead could pay off, and\napplications could work with compressed data transparently, and so not\neven noticing the slowdown due to the extra effort for\ncompression/decompression.\n\nThis technique can be very beneficial in a variety of scenarios where\nRAM availability is critical.  For example, in-memory caching systems\nlike Memcached or Redis could store more data using the same resources\nthereby optimizing resource usage.  Another use case is to use\ncompression for in-memory data containers, Ã  la NumPy's ndarray or\nPandas' DataFrame, allowing for improved memory usage and potentially\nallow for accelerated computations.\n\nIn our talk, we will explain first why we are in a moment of computer\nhistory that [in-memory compression can be beneficial for modern\napplications] [1].\n\nThen, we will introduce [Blosc] [2], a high speed\nmeta-compressor, allowing other existing compressors (BloscLZ, LZ4,\nSnappy or even Zlib) to leverage the SIMD and multithreading framework\nthat it provides and help achieving extremely fast operation\n(frequently faster than a plain memcpy() system call).\n\nFinally, we will show some existing data handling libraries ([Bloscpack] [3], [PyTables] [4], [BLZ] [5]) -- all written in Python -- that\nalready use Blosc today for fulfilling the promise of faster operations by\ndoing in-memory compressing.\n\n[1]: http://www.pytables.org/docs/CISE-12-2-ScientificPro.pdf\n[2]: http://www.blosc.org\n[3]: https://github.com/Blosc/bloscpack\n[4]: http://www.pytables.org\n[5]: http://continuum.io/blog/blz-format"
